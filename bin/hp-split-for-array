#!/usr/bin/env python

#
# - Split a fasta file.
# - Create an index.
# - Generate Array Job QSUB.
#

import argparse
import logging
import itertools
import os

PWD = os.path.dirname(os.path.realpath(__file__))
TMP_DIR = default=os.path.join(PWD, 'tmp')

from Bio import SeqIO

import tempfile

def parse_args():
    ''' return arguments
        >>> args = parse_args()
    '''

    parser = argparse.ArgumentParser()
    parser.add_argument('--log', default='/dev/stderr', help='log file (default=stderr)')
    parser.add_argument('--verbose', default=False, action='store_true')
    parser.add_argument('--chunk-size', default=10000, type=int, help='number of sequences per chunk')
    parser.add_argument('--directory', type=str, required=True, help='chunk and job file output directory')
    parser.add_argument('--fasta-file', type=str, required=True, help='input fasta file', default='/dev/stdin')
    parser.add_argument('--chunk-cmd', type=str, default=False, help='run cmd after generating chunk with %(chunk)s being set to file path')
    parser.add_argument('--tmp', default=TMP_DIR)

    return parser.parse_args()


def post_chunk_script(command, out_file):
    ''' Run the post chunk script '''

    logging.info(command)
    os.environ['OUT_FILE'] = out_file
    status = os.system(command)

    logging.info('exit status: "%s"' % status)

    return status


def setup_logging(logfile='/dev/stderr', verbose=False):

    if verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO

    return logging.basicConfig(filename=logfile, level=level)


def chunk_emitter(iterable, size):
    it = iter(iterable)
    item = list(itertools.islice(it, size))
    while item:
        yield item
        item = list(itertools.islice(it, size))


def main():
    '''
        >>> main() # stuff happens
    '''


    args = parse_args()

    setup_logging(logfile=args.log, verbose=args.verbose)

    logging.info('args=%s' % args)

    chunk_index = {}

    try:
        os.mkdir(args.directory)
    except OSError:
        logging.info('warning! output directory %s exists' % args.directory)

    if not os.path.exists(TMP_DIR):
        logging.info('creating temp directory: %s' % TMP_DIR)
        os.mkdir(TMP_DIR)

    with open(args.fasta_file) as handle:
        logging.info('reading from %s' % args.fasta_file)
        records = SeqIO.parse(handle, 'fasta')
        chunks = chunk_emitter(records, args.chunk_size)

        for i, chunk in enumerate(chunks):

            logging.info('writing chunk %s' % i)

            output_file = os.path.join(args.directory, 'chunk-%s.fasta' % i)

            chunk_index[i] = output_file

            with tempfile.NamedTemporaryFile(mode='w', delete=False, dir=args.tmp) as output_handle:
                logging.info('writing to %s' % output_handle.name)
                SeqIO.write(chunk, output_handle, 'fasta')

                logging.info('moving to %s' % output_file)
            os.rename(output_handle.name, output_file)

            if args.chunk_cmd:
                cmd = args.chunk_cmd % { 'chunk': os.path.realpath(output_file) }
                logging.info('running cmd: %s' % cmd)
                os.system(cmd)

    index_file = os.path.join(args.directory, 'index.txt')
    logging.info('saving index to: %s' % index_file)
    with open(index_file, 'w') as handle:
        for k in chunk_index:
            print >> handle, '%s,%s' % (k, chunk_index[k])

if __name__ == '__main__':
    main()

